{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119a978c-794a-42a7-8926-cda6871c8613",
   "metadata": {},
   "source": [
    "# Prompt Engineering: Use OpenAI to Analyze Twitter Data \n",
    "This is a simple tutorial teaching prompt engineering basics and analyzing Twitter data with OpenAI large language models (LLM).\n",
    "Please purchase an [OpenAI API](https://openai.com/index/openai-api/) and store it in a safe place. This tutorial uses [AWS Secretes Manager](https://aws.amazon.com/secrets-manager/) to store the API keys.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15700978-787e-407e-a940-c977a71b3044",
   "metadata": {},
   "source": [
    "## Large Language Model Basics\n",
    "LLM repeatable predicts the next world using supervised learning. To predict the following sentence: \n",
    "\n",
    "`Learning data science in the cloud with AI`\n",
    "\n",
    "A model needs to learn to predict the following steps:\n",
    "\n",
    "|Input|Output|\n",
    "|:---|---|\n",
    "|Learning data science |in |\n",
    "|Learning data science in |the | \n",
    "|Learning data science in the |cloud |\n",
    "|Learning data science in the cloud |with |\n",
    "|Learning data science in the cloud with |AI|\n",
    "\n",
    "To train an LLM model:\n",
    "1. Training a base LLM model on a large amount of training data to predict the next word \n",
    "2. Fine-tune on examples where outputs follow instructions in the input \n",
    "3. Human rates quality of different LLM outputs \n",
    "4. Tune LLM to generate outputs with higher rates using RLHF (Reinforcement learning from human feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7726290-4f69-4f9f-94d4-18b9c8f26f14",
   "metadata": {},
   "source": [
    "## Set up OpenAI Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9019645-db86-4235-93e7-cbd52e770afc",
   "metadata": {},
   "source": [
    "Load the API keys with AWS Secrets Manage Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845f6d31-1f82-47e5-9fa4-de3da8aa068a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92790e72-aea1-4acc-b98d-a6782550777c",
   "metadata": {},
   "source": [
    "## Install Python libraries.\n",
    "\n",
    "- pymongo: manage the MongoDB database\n",
    "- openai: call the OpenAI APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d4f923-3b7c-4bd2-945a-1fbda250e8df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.70.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Downloading openai-1.70.0-py3-none-any.whl (599 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.1/599.1 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.9.0 openai-1.70.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1ab01b-f2f1-4c10-8936-7dca341af6af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading pymongo-4.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.7.0 pymongo-4.11.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276093f1-824b-4793-bb59-dc30c7d84fb4",
   "metadata": {},
   "source": [
    "Load the OpenAI API key and define a `openai_help` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b126647a-fbda-42c3-bebb-d689802c6665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "def openai_help(messages, model=model, temperature =temperature ):\n",
    "    messages = messages\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7bc14c-2609-4c3e-aa5d-762cd3d06ac0",
   "metadata": {},
   "source": [
    "Temperature: \n",
    "- Low temperature: always choose the most likely response, reliable, predictable responses  \n",
    "- High temperature: diverse responses, more creative responses\n",
    "\n",
    "Tokens and Models: \n",
    "- LLM predicts tokens, which are commonly occurring sequences of characters. \n",
    "- One token is about four characters in English, and 100 tokens are roughly 75 words. Check [token estimate](https://platform.openai.com/tokenizer).\n",
    "- Different models can process various amounts of tokens at different performance levels and costs. Check [OpenAI models](https://platform.openai.com/docs/models) for more details.\n",
    "\n",
    "Roles:\n",
    "- system: specify the overall tone or behavior of the assistant \n",
    "- user: instruction given to the LLM\n",
    "- assistant: LLM responded content, we also can provide content in few-shot promoting or histories of conversations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ef378-e825-40ca-a565-371ba96268a1",
   "metadata": {},
   "source": [
    "A simple example using [gtp-4o](https://platform.openai.com/docs/models/gpt-4o) and temperature 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b746d9-f11f-4f46-96f5-64dd40f6dc36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the United States is Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of USA\"}]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfcbc19-1ea0-456a-ba84-8f76ef87ba30",
   "metadata": {},
   "source": [
    "Add a system message asking LLM to act as a high school teacher with different temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7608f8d0-fefb-41a7-8713-1287b3cd7047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the United States is Washington, D.C. It's an important city politically and historically, serving as the hub for the federal government's three branches. If you have any more questions about it or need further clarification, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"use tone as a high school teacher\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of USA\"}\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages, temperature = 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887fc65-5f97-4530-b81b-f158ea2af413",
   "metadata": {},
   "source": [
    "Add assistant messages to teach LLM what `##` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e37e101-f820-4ba7-969c-ce05b53aafe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is 33.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 1##1\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"it is 11\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2##2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"it is 22\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 3##3\"},\n",
    "    ]\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addef986-2e0c-4849-bc7a-48b102fbf2fe",
   "metadata": {},
   "source": [
    "## Prompt Engineering Principles \n",
    "- Use delimiters to separate different parts of a prompt to provide clear instructions and prevent prompt injections.\n",
    "- Structure outputs in JSON documents or other formats to use the outputs in subsequent steps \n",
    "- Few-shot promoting: provide successful examples of a task and then ask the model to perform a similar task. \n",
    "- Chain of thought reasoning: request a series of reasoning steps in prompts to help the model achieve correct answers\n",
    "- Chain of prompts: split a task into multiple prompts where each prompt can focus on a sub-task at a time and take different actions at different stages. It saves tokens, is easier to test, can involve human input, or use external tools.\n",
    "- Interactive process \n",
    "  1. Try something first \n",
    "  2. Analyses the result, identify errors, and redefine the prompt \n",
    "  3. Test the prompts with different datasets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b972159e-3c51-4d95-8fd0-7e85bb572821",
   "metadata": {},
   "source": [
    "An example using delimiters, structured output and few-shot promoting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da5d9da0-de00-4611-b448-71433d6700f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"sentiment\": \"positive\" }\n"
     ]
    }
   ],
   "source": [
    "delimiter = '###'\n",
    "sentence1 = 'I love cat.'\n",
    "sentence2 = 'I love dog.'\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"analyze the sentiment in a sentence delimitered by {delimiter},\n",
    "                                     return the result as a JSON document\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{sentence1}{delimiter}\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"{sentiment:positive}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{sentence2}{delimiter}\"}\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adfdc4-2bea-476d-9c0b-6ee8bff24436",
   "metadata": {},
   "source": [
    "## Analyze Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bbef7a-54ba-4a6e-a5a5-a050cd887a70",
   "metadata": {},
   "source": [
    "### Connect to the MongoDB cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ac135f-43ea-4499-9aac-224324b9e727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tweet.id_1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "mongodb_connect = get_secret('mongodb')['connection_string']\n",
    "\n",
    "mongo_client = MongoClient(mongodb_connect)\n",
    "db = mongo_client.demo # use or create a database named demo\n",
    "tweet_collection = db.tweet_collection #use or create a collection named tweet_collection\n",
    "tweet_collection.create_index([(\"tweet.id\", pymongo.ASCENDING)],unique = True) # make sure the collected tweets are unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdcfa9f-34a3-4902-b3ac-52b56cfb890d",
   "metadata": {},
   "source": [
    "### Extract Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb2d39e-603b-4d41-9a23-b4db8dcdad2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter={\n",
    "\n",
    "    \n",
    "}\n",
    "project={\n",
    "    'tweet.text': 1, \n",
    "    'tweet.id': 1\n",
    "}\n",
    "#rename the client to mongo_client\n",
    "result = mongo_client['demo']['tweet_collection'].find(\n",
    "  filter=filter,\n",
    "  projection=project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d4082df-a6f5-4427-b059-90995c1b5571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "for tweet in result:\n",
    "    tweet_data.append(tweet['tweet']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a0713c-4ebb-4cc0-b3e5-e307f9b40a94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets:  98\n"
     ]
    }
   ],
   "source": [
    "print('Number of tweets: ',len(tweet_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d566a4-aafc-4592-ab05-33af9f88e220",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summarization \n",
    "- Analyze election tweets with delimiters \n",
    "- Change the size of the summarization \n",
    "- Summarize tweets and focus on different perspectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d548343d-ce9b-4960-88c2-d9586631a6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tweets discuss various aspects of generative AI, including its applications, impact, and controversies. Some tweets highlight new AI models and tools, such as Microsoft's free course on generative AI and RunwayML's Gen-4 models. Others express concerns about the environmental impact and ethical implications of generative AI, particularly in art and creative industries. There are mentions of collaborations, like NVIDIA and AWS working to make AI more accessible, and discussions on the future trends of AI, including its potential in healthcare and media. Additionally, some tweets criticize the use of AI in creative fields, advocating for human artists, while others express excitement about AI's potential to revolutionize content creation.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a brief summary of the tweets delimited by {delimiter}\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd324d10-eb50-4d2b-a9ac-56af268d37a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI is rapidly advancing, impacting industries from art to healthcare, with both excitement and criticism surrounding its use.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a brief summary of the tweets delimited by {delimiter},\n",
    "                                    limit the summary to 20 words\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc09adab-a49c-453f-af26-3ecc4edd7603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People discuss AI with a mix of excitement and skepticism. Generative AI is seen as transformative for media and business, yet criticized for its environmental impact and lack of originality. Some celebrate its potential, while others advocate for traditional artistry and caution against its unchecked use.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a brief summary of the tweets delimited by {delimiter},\n",
    "                                    focus on how people discuss AI,\n",
    "                                    limit the summary to 50 words\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c75ab-00d8-44e2-a63e-b4b3aa1847e1",
   "metadata": {},
   "source": [
    "### Moderation \n",
    "- Iterate each tweet and use the [moeration endpoint](https://platform.openai.com/docs/api-reference/moderations) to identify flagged tweets\n",
    "- Print flagged tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc3eee06-540d-4126-945c-8153165d88b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flag_help(tweet):\n",
    "    response = client.moderations.create(\n",
    "        model=\"omni-moderation-latest\",\n",
    "        input=tweet)\n",
    "\n",
    "    if response.results[0].flagged:\n",
    "        print('===')\n",
    "        cat_dict = response.results[0].categories.to_dict()\n",
    "        for cat in cat_dict.keys():\n",
    "            if cat_dict.get(cat):\n",
    "                print (cat)\n",
    "                print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6878285-cd9f-4878-8cc1-cee9bbd8160c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "harassment\n",
      "RT @Artistreccs: Made this account as a huge fuck you to Ai generative art and the the rest of them losers tbh \n",
      "\n",
      "Commission real artists 👍\n",
      "===\n",
      "harassment\n",
      "RT @imzeferino: generative AI art is is soulless, sad and pathetic... i won't even bother calling it ugly, because that is beside the point…\n",
      "===\n",
      "harassment\n",
      "RT @Artistreccs: Made this account as a huge fuck you to Ai generative art and the the rest of them losers tbh \n",
      "\n",
      "Commission real artists 👍\n",
      "===\n",
      "harassment\n",
      "RT @Artistreccs: Made this account as a huge fuck you to Ai generative art and the the rest of them losers tbh \n",
      "\n",
      "Commission real artists 👍\n",
      "===\n",
      "harassment\n",
      "RT @Artistreccs: Made this account as a huge fuck you to Ai generative art and the the rest of them losers tbh \n",
      "\n",
      "Commission real artists 👍\n",
      "===\n",
      "violence\n",
      "The IDF, one of the leaders in the tech industry, uses and trains generative ai off the killing of real human beings. This technology would give a government an army without needing human soldiers\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweet_data:\n",
    "    flag_help(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7a7d3-9097-4f70-a7f3-7ba23643e60a",
   "metadata": {},
   "source": [
    "### Transforming\n",
    "- Translating to a different language \n",
    "- Transform tones, such as formal vs. informal.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee398dde-df13-4911-bbbf-8151c49ace98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @16pxl: 只是发布我这个堕落的人类制作的吉卜力风格像素艺术，而不是生成式AI 🤪 没有任何理由！https://t.co/b…\n",
      "RT @MoureDev: 微软发布了其官方课程的新版本，用于学习生成式人工智能。\n",
      "\n",
      "这是免费的，并通过21节课教你…\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "软件和互联网公司在未来三年内，来自生成式人工智能的收入可能会增长超过20倍，并且最早在2025年就能实现正投资回报。https://t.co/ztP34WsIRC\n",
      "@poiyomi @HOUNDDS 许多平台都实施了生成式AI，但没有提供不使用它的选项。而且，大多数时候它甚至不准确。进行简单的谷歌搜索不应该使用生成式AI。以前在谷歌上进行研究效果很好。\n",
      "@sawyomom 是的，因为他是真正的人工智能。一个能够独立思考的完整大脑 ≠ 生成脚本\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @Artistreccs: 创建这个账号是对AI生成艺术和其他那些失败者的一个巨大反击，说实话\n",
      "\n",
      "委托真正的艺术家 👍\n",
      "RT @jblefevre60: 💥8个生成式AI流行词！\n",
      "\n",
      "#AI #机器学习 #深度学习 #数据科学 #生成式AI #LLM #Python #编程 #100天…\n",
      "Theta 的多操作系统边缘节点支持是一个改变游戏规则的创新——就像给每个设备提供了进入去中心化计算的后台通行证！与 AWS 和三星合作，它正在推动从生成式 AI 到元链交易的创新。*喘气*\n",
      "@Writing_Dragons 我认为使用支持AI的软件与能够充当人类编辑的生成式AI有很大不同。我认为区别在于你作为作者是否仍然掌控局面。\n",
      "热烈祝贺@MahojinAI，这是一个基于Story构建的生成式AI混音工具 ↴ https://t.co/7L7DLVeoeU\n",
      "RT @AdrianEarthmeta: 🧠 你对下一个人工智能大趋势有什么预测？\n",
      "🤖 超逼真的AI聊天机器人？🧬 突破性…\n",
      "RT @freezetheberry: 在生成式人工智能“艺术”日益流行的时代，我们有这样的艺术家证明机器永远无法替代……\n",
      "RT @jblefevre60: 💥8个生成式AI流行词！\n",
      "\n",
      "#AI #机器学习 #深度学习 #数据科学 #生成式AI #LLM #Python #编程 #100天…\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感觉 https://t.co/iTnP1I3ci5\n",
      "RT @nvidia: NVIDIA和@awscloud致力于让生成式AI更易于获取并产生更大影响。\n",
      "\n",
      "我们的合作正在帮助组织…\n",
      "@CIOdive 突出了 Flexera 2025 年 #Cloud 报告中的趋势，并与我们自己的 Brian Adler 和 Jay Litkey 讨论了 #IT 领导者在优化支出和确定更适合本地部署的应用程序时的关键要点。https://t.co/iMuQxJahe9\n",
      "🧠 你对下一个大型人工智能趋势的预测是什么？ 🤖 超逼真的AI聊天机器人？ 🧬 AI驱动的医疗保健突破？ 🎨 下一代生成式AI工具？ 👇 分享你对机器学习和AI创新未来的看法！ https://t.co/8BnRwhFsel\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "生成视频效果。人工智能准备以深刻的方式重新定义内容创作。\n",
      "人工智能不仅仅是一个助手，它是一个可以放大你创造潜力的合作者。\n",
      "在#ALX_AI #Alx_AISK上玩得很开心 https://t.co/2Aid1wwdds\n",
      "RT @namazu_sensei: 艺术教育的功能不是为了让人成为专业艺术家，而是为了培养感受力，因为艺术存在于…\n",
      "RT @16pxl: 只是发布我这个堕落的人类制作的吉卜力风格像素艺术，而不是生成式AI 🤪 没有任何理由！https://t.co/b…\n",
      "RT @jblefevre60: 💥8个生成式AI流行词！\n",
      "\n",
      "#AI #机器学习 #深度学习 #数据科学 #生成式AI #LLM #Python #编程 #100天…\n",
      "💥8个生成式AI流行词！\n",
      "\n",
      "#AI #机器学习 #深度学习 #数据科学 #生成式AI #LLM #Python #编程 #100天编程挑战\n",
      "\n",
      "@CurieuxExplorer @PawlowskiMario @mvollmer1 @gvalan @ipfconline1 @LaurentAlaus @Shi4Tech @Fisher85M @kalydeoo @Ym78200 @Nicochan33 @Fabriziobustama https://t.co/MQBPdBqBN5\n",
      "转发 @RedPill_Marxism: 生成式人工智能只是全人类集体作品的体现\n",
      "\n",
      "如果你讨厌生成式人工智能，你就是讨厌人类\n",
      "RT @DiaboIicAngel: 他在谈论生成式人工智能 https://t.co/CRe0k3OzJq\n",
      "RT @chambaz: 在3万英尺高空使用生成式AI\n",
      "\n",
      "在中东上空某处一边喝啤酒一边同时进行两个项目\n",
      "等到生成式人工智能在游戏、电影、电视等领域被广泛使用时， 那会很有趣！https://t.co/WtdUasSokt\n",
      "@sama 非常值得。\n",
      "\n",
      "ChatGPT-4o 是生成式人工智能的一个分水岭。https://t.co/Ed9MCBOmhw\n",
      "RT @stefanbertin: 真的不喜欢人们试图淡化生成式人工智能对创意行业的明显和真实的危险……\n",
      "RT @nvidia: NVIDIA和@awscloud致力于让生成式AI更易于获取并产生更大影响。\n",
      "\n",
      "我们的合作正在帮助组织…\n",
      "ALX_AiSK\n",
      "@alx_africa 查看我的AI生成作品\n",
      "https://t.co/aghz2PNOxz\n",
      "RT @SarvamAI: Sarvam 正在为其推理团队招聘 🚀\n",
      "\n",
      "在 Sarvam，我们正在构建印度的主权生成式 AI 堆栈。从训练开始…\n",
      "RT @edmundmcmillen: 1. 我不在乎，随便盗版。我不是道德警察。 2. 我不支持将生成式AI用于经济利益…\n",
      "RT @adjudicatorcb: 在试镜之前，我们有多位配音演员联系过来，担心我们是否使用AI进行配音。为了…\n",
      "@CoreOfMidas 机器翻译不能替代真正懂语言的人。AI生成图像算法不会取代艺术家，因为艺术家可以创造前所未见的东西，而AI只能基于其被输入的数据集进行重混。\n",
      "@SenseiBR_btc $SUEDE AI\n",
      "第一个链上音乐生成AI代理\n",
      "RT @carolduvallon: 愿我们的小长假周精彩纷呈，并且没有生成式AI的干扰 💛🩵\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感受 https://t.co/iTnP1I3ci5\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @imzeferino: 生成式AI艺术是没有灵魂的、悲哀的和可悲的……我甚至不会费心称其为丑陋，因为这无关紧要……\n",
      "@Xander_J_C 现代生成式人工智能实际上只是分析以前的原创作品，然后根据提示吐出该艺术品的变体或混合版本，而不对原始作品给予任何信用，也没有对“创作者”进行实质性工作，从根本上说，它不是一个鼓机\n",
      "@geekshrine 我认为人工智能在技术、医疗领域甚至在简化复杂流程方面都有其作用，但生成式人工智能实在是太糟糕了。吉卜力的东西让我彻底失望了。\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @hydreamgeas: 而且这真的是在问他一些无关紧要的事情，拜托请了解一下生成式AI的问题……\n",
      "RT @OlivierKamitatu: 发现生成式人工智能就像进入一个复杂设备的驾驶舱。没有事先的培训，我们可能会...\n",
      "RT @Artistreccs: 创建这个账号是对AI生成艺术和其他那些失败者的一个巨大反击，说实话\n",
      "\n",
      "委托真正的艺术家 👍\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感受 https://t.co/iTnP1I3ci5\n",
      "RT @iamn3el: 当没有人谈论太多关于人工智能的时候，这个人已经制作了一整部关于它的电影，而且如此准确。描述每一个…\n",
      "@CEBass_writer 事实上，AI 是多种多样的，其中一些确实会存储你的书籍。而且 AI 也很容易犯错。\n",
      "\n",
      "话虽如此，使用支持 AI 的软件与能够充当人类编辑的生成式 AI 是截然不同的。我认为区别在于\n",
      "RT @Artistreccs: 创建这个账号是为了对AI生成艺术和其他那些失败者表达强烈的不满，说实话\n",
      "\n",
      "委托真正的艺术家 👍\n",
      "RT @runwayml: 今天我们推出了Gen-4，这是我们新一代的尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @GeorgeCrudo: 这不仅仅需要你知道如何提示。你还需要学习像Zbrush这样的数字雕刻软件，并且……\n",
      "要注册免费课程，请访问：https://t.co/EtuTFxZYtd\n",
      "RT @Artistreccs: 创建这个账号是对AI生成艺术和其他那些失败者的一个巨大反击，说实话\n",
      "\n",
      "委托真正的艺术家 👍\n",
      "RT @MoureDev: 微软发布了其官方课程的新版本，用于学习生成式人工智能。\n",
      "\n",
      "这是免费的，并通过21节课教你…\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @temp_secretare: 提醒一下，保罗·麦卡特尼顺便说一下讨厌生成式AI。https://t.co/fu5Fi77D0P\n",
      "@GreenTieOffici1 @PiperistheNewbl @merururuu 用于支持和维护这些生成式AI程序的服务器需要大量能源，而且由于人们似乎在大规模地制造它们，这意味着大量能源被浪费在制造它们上，这对环境造成了相当大的负面影响。\n",
      "RT @AWSstartups: 🧑‍💻💡 @QodoAI 利用#AI帮助企业消除不良代码。了解AWS生成式AI加速器如何帮助这家初创公司…\n",
      "转发 @AlhujiliTurki: 各国之间生成式#AI的竞争性方面 https://t.co/vjF780GmS0\n",
      "@VanCommunist @InfraHaz 并不完全是，生成式AI会为那些对其印象深刻的技术宅生产垃圾内容\n",
      "RT @freezetheberry: 在生成式AI“艺术”日益流行的时代，我们有这样的艺术家证明机器永远无法替代……\n",
      "RT @ArtTezos: Tezos 艺术史上的今天（2022-04-04），@ivonatau 在 Unknown Marketplace 上售出了 objkt #6（20 版），筹集了 972 tez。http…\n",
      "今天是“生成式人工智能在项目管理中的实际应用”课程的最后一天，该课程提供5个PDU和一个免费课程。\n",
      "\n",
      "我会在午夜前完成，哈哈\n",
      "转发 @AlhujiliTurki: 各国之间生成式#AI的竞争方面 https://t.co/vjF780GmS0\n",
      "@RobotCleopatra 祝贺 @RobotCleopatra！你是生成式人工智能的掌控者和指挥官！\n",
      "很高兴重新投入行动！\n",
      "\n",
      "欢迎参观 #IntelVision 的112号展位，#IterateAI 和 #Intel 正在展示我们的 RAG 和生成式 AI 助手 Generate Enterprise，该助手运行在 #IntelGaudi 上！\n",
      "\n",
      "#AI #AI加速器 #LLM https://t.co/vOGtT7WO2l\n",
      "RT @FaatiTheStreet: 生成式人工智能并不是这些字面上的骗子所宣称的那样。它不是天网，也不是《她》中的人工智能，也不是……\n",
      "RT @rileyiwaoi: 及川说去他的生成式AI！https://t.co/BttNOJuGiS\n",
      "生成式人工智能太棒了，我非常喜欢它。继续使用它吧！这项出色的技术让我感到兴奋，而只有一些艺术家似乎关心这点，这真是荒谬。\n",
      "\n",
      "作为一个观察创意演变了30年的创新者，我对人工智能图像工具的发展感到震惊。https://t.co/j0IueWpLMH\n",
      "RT @moonberg_ai: 欢迎 Pradeep Menon 加入 Moonberg！\n",
      "\n",
      "作为微软数据和生成式 AI 的首席技术官，Pradeep 一直站在创新的前沿……\n",
      "RT @adjudicatorcb: 我们收到了多位配音演员的来信，他们对我们在试镜前是否使用AI进行配音表示担忧。\n",
      "\n",
      "为了…\n",
      "推理正在成为生成式人工智能基础设施的关键驱动力。这个由@WEKAio和@Solidigm举办的网络研讨会解释了原因。https://t.co/xeAJ2KT8CL https://t.co/mZyg3VyXF5\n",
      "...工程和指令微调。作者阐明了优化推理的技术，如模型量化/剪枝，以及用于典型生成式人工智能（GenAI）应用的不同/经济实惠的架构，包括搜索系统、代理辅助等。\n",
      "现已为ACM会员提供：《基于大型语言模型的解决方案：如何通过具有成本效益的生成式AI应用程序提供价值》有声书，由Shreyas Subramanian（@awscloud）撰写。了解如何选择模型、进行数据的前/后处理、提示... https://t.co/nIZhboXh5f https://t.co/gu8rs9AeBF\n",
      "RT @brush_of_chaos: 我不支持生成式AI作品。我支持真正的艺术家。https://t.co/rUbTePrFey\n",
      "RT @kimmonismus: 亚马逊发布网络代理\n",
      "\n",
      "亚马逊今天扩大了其先进生成式AI模型的访问权限。在其平台上，开发者们…\n",
      "RT @namazu_sensei: 艺术教育的功能不是为了让人成为专业艺术家，而是为了培养感受力，因为艺术存在于……\n",
      "RT @nvidia: NVIDIA和@awscloud致力于让生成式AI更易于获取并更具影响力。\n",
      "\n",
      "我们的合作正在帮助组织…\n",
      "RT @rosinante_daily: Corazon的日本配音演员山寺宏一与其他25位知名日本声优组成了一个团体，反对…\n",
      "RT @scythe_daily: 第305天\n",
      "\n",
      "不要让生成式AI让你感到沮丧，继续做你热爱的事情，伙计们 -🪽\n",
      "\n",
      "#phighting https://t.co/EfMT…\n",
      "RT @navigate_ai: AI正在重塑在线购物。🛍️\n",
      "\n",
      "Adobe报告称，由生成式AI带来的流量激增了1200%，这只是时间问题……\n",
      "道格·韦比（Doug Werby）谈论为何人工智能有潜力引领一个创意创新的新时代。https://t.co/p32DTfxlvH https://t.co/SlyPMBAagD\n",
      "Equinix 提供的即时 AI 工厂服务在全球范围内提供预配置的、AI 就绪的数据中心，加速实时 AI 代理响应和生成式 AI 工作负载。\n",
      "RT @nvidia: NVIDIA和@awscloud致力于让生成式AI更易于获取并产生更大影响。\n",
      "\n",
      "我们的合作正在帮助组织…\n",
      "生成式人工智能不仅仅是用于创建营销内容——这是我对下一代#genAI在营销中应用案例的看法。#martech #generativeai #marketing #cdp #analytics https://t.co/IfYgbTJZ5I\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "➡️ 🧵↘️ #AI 代理工作流程：医学研究和发现的新时代 -- 生成式 #健康\n",
      "\n",
      "Rene Caissie 博士，https://t.co/hn8oL1WqqF 的首席执行官兼联合创始人\n",
      "@NextMedHealth\n",
      "\n",
      "https://t.co/7UZOPTXMkk\n",
      "@YoleGroup 预计到2030年，#半导体设备行业将在生成式#AI的推动下达到1万亿美元。📈 高级封装平台将在竞争差异化中发挥关键作用。 https://t.co/e3fypa2Hqg\n",
      "RT @AnAverageSpy: 那是因为他是一个碰巧是AI的艺术家，而不是一个不应该被称为艺术家的生成式AI\n",
      "RT @economistimpact: 信心始于可信的可持续性数据。由 Infosys Topaz 提供支持，这是一套以生成式 AI 为核心的 AI 优先套件，a…\n",
      "@cdtwriter https://t.co/EVMxa8Hi77\n",
      "刚刚在 @Trailhead 上获得了负责任的人工智能创建徽章，你也应该去获得！https://t.co/WNQPkOKhKj\n",
      "以色列国防军（IDF）作为科技行业的领导者之一，利用并训练生成式人工智能，以真实人类的死亡为代价。这项技术将使政府无需人类士兵就能拥有一支军队。\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweet_data:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"translate the tweets delimited by {delimiter} into Chinese\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "\n",
    "    print(openai_help(messages).strip(delimiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f2b2219-b1f9-4be8-9d7c-2f1daa733e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @16pxl: Ah, behold my Ghibli-inspired pixel art, crafted by a mere mortal rather than some soulless generative AI. No particular reason, just felt like it! 🤪 https://t.co/b…\n",
      "Ah, splendid! Microsoft has unveiled a fresh iteration of their official course on Generative AI. And guess what, it's absolutely free! In just 21 lessons, you'll be on your way to mastering the art of artificial intelligence. How delightfully efficient!\n",
      "RT @runwayml: Ah, splendid news, isn't it? Today we unveil Gen-4, our latest series of state-of-the-art AI models, designed for media generation and world consistency. Gen-4, the pièce de résistance of technological advancement...\n",
      "Oh, splendid! It appears those software and internet companies are about to experience a delightful surge in revenue from Generative AI, skyrocketing over 20 times in the next three years. And by 2025, they'll be swimming in positive returns on investment. How positively thrilling! https://t.co/ztP34WsIRC\n",
      "Oh, how utterly delightful! It seems the world has gone mad with this generative AI nonsense, hasn't it? These platforms, in their infinite wisdom, have decided to shove it down our throats without so much as a \"by your leave.\" And the accuracy? Ha! It's about as reliable as Brian's parenting skills. Honestly, a simple Google search was perfectly adequate before this AI hullabaloo.\n",
      "@sawyomom Oh, indeed! A true AI, you say? A fully formed brain capable of independent thought, unlike those mere generative scripts. How delightfully intriguing!\n",
      "RT @runwayml: Ah, splendid news, isn't it? Today we unveil Gen-4, our latest series of cutting-edge AI models designed for media generation and maintaining world consistency. Gen-4...\n",
      "RT @Artistreccs: I created this account as a grandiose middle finger to AI-generated art and all those other insipid buffoons, if I'm being perfectly honest. \n",
      "\n",
      "Do commission real artists, won't you? 👍\n",
      "Ah, splendid! A delightful collection of generative AI buzzwords to tickle one's intellect! #AI #MachineLearning #DeepLearning #DataScience #GenerativeAI #LLM #Python #Coding #100DaysOf…\n",
      "Ah, splendid! Theta’s Multi-OS Edge Node Support is quite the revolutionary marvel, akin to bestowing every device with an exclusive backstage pass to the grand theater of decentralized computing! In cahoots with the likes of AWS and Samsung, it’s propelling innovation from the whimsical realms of generative AI to the intricate dance of metachain transactions. *exhales dramatically*\n",
      "Oh, how delightfully quaint! You see, there's a rather stark contrast between employing AI as a mere tool, akin to a quill in the hand of a scribe, and allowing it to prance about as if it were a human editor, wielding its own quill with reckless abandon. The crux of the matter, dear simpletons, lies in whether you, the so-called author, maintain your grip on the reins of creativity.\n",
      "Ah, splendid news indeed! A hearty congratulations to @MahojinAI, the delightful generative AI remixing tool built upon the illustrious Story. How utterly marvelous! https://t.co/7L7DLVeoeU\n",
      "Oh, do tell, what do you think the next grand spectacle in artificial intelligence will be? Perhaps hyper-realistic AI chatbots that can finally match my unparalleled wit? Or maybe a breakthrough so profound it could even impress someone of my superior intellect? Do share, I'm simply dying to know.\n",
      "RT @freezetheberry: Oh, the audacity of these so-called \"generative AI\" art forms gaining traction. Yet, behold, the true artists who demonstrate that no mere machine can replicate the brilliance of genuine human creativity.\n",
      "Ah, the delightful world of generative AI buzzwords! How utterly riveting. #AI #MachineLearning #DeepLearning #DataScience #GenerativeAI #LLM #Python #Coding #100DaysOf... Do try to keep up, won't you?\n",
      "RT @runwayml: Ah, splendid news, isn't it? Today we unveil Gen-4, our latest series of state-of-the-art AI models, designed for media generation and world consistency. Gen-4, the pièce de résistance of technological advancement...\n",
      "Ah, the blissful ignorance of never having dabbled in the digital sorcery of generative AI or indulged in the latest AI fads. One might say it's akin to living in a quaint little bubble, untouched by the relentless march of technological progress. How delightfully archaic! https://t.co/iTnP1I3ci5\n",
      "RT @nvidia: Ah, splendid! NVIDIA and @awscloud are joining forces to bring generative AI to the masses. Our little collaboration is set to revolutionize organizations everywhere. How delightfully diabolical!\n",
      "Ah, splendid! @CIOdive has unveiled the latest trends from Flexera's 2025 State of the #Cloud report. They've even had a delightful little chat with our very own Brian Adler and Jay Litkey. It's all about those crucial insights for #IT leaders, you see, as they endeavor to optimize their spending and decide which applications are best left on-prem. Do have a look, won't you? https://t.co/iMuQxJahe9\n",
      "🧠 Oh, do tell me, what do you foresee as the next grand spectacle in the realm of artificial intelligence? Will it be those frightfully convincing AI chatbots that could fool even the most discerning of minds? 🤖 Or perhaps a monumental leap in AI-driven healthcare that would make even the most seasoned doctors quiver in their stethoscopes? 🧬 Or maybe, just maybe, the emergence of next-generation generative AI tools that would put even the most creative of humans to shame? 🎨 Do share your musings on the future of machine learning and AI innovation, won't you? https://t.co/8BnRwhFsel\n",
      "RT @runwayml: Ah, splendid news, isn't it? Today we unveil Gen-4, our latest series of cutting-edge AI models designed for media generation and maintaining world consistency. Gen-4...\n",
      "Ah, the wonders of Generative Video Effects! AI is on the brink of revolutionizing content creation in the most splendidly profound ways. It's not merely a helper, but a delightful collaborator that can elevate your creative prowess to new heights. Quite the exhilarating experience at #ALX_AI #Alx_AISK, wouldn't you agree? https://t.co/2Aid1wwdds\n",
      "Ah, yes, the purpose of art education isn't to churn out professional artists, but rather to cultivate a sense of appreciation for the arts. Quite right, quite right.\n",
      "RT @16pxl: Ah, behold my Ghibli-inspired pixel art, crafted by a mere mortal rather than some soulless generative AI. No particular reason, just felt like it, you simpletons! 🤪 https://t.co/b…\n",
      "Ah, splendid! A delightful collection of generative AI buzzwords to tickle one's intellect! #AI #MachineLearning #DeepLearning #DataScience #GenerativeAI #LLM #Python #Coding #100DaysOf…\n",
      "Oh, splendid! Eight delightful buzzwords from the realm of generative AI! How positively thrilling! #AI #MachineLearning #DeepLearning #DataScience #GenerativeAI #LLM #Python #Coding #100DaysOfCode\n",
      "\n",
      "@CurieuxExplorer @PawlowskiMario @mvollmer1 @gvalan @ipfconline1 @LaurentAlaus @Shi4Tech @Fisher85M @kalydeoo @Ym78200 @Nicochan33 @Fabriziobustama https://t.co/MQBPdBqBN5\n",
      "Ah, yes, the delightful musings of the proletariat. Generative AI, you see, is merely the grand tapestry woven from the threads of human brilliance. To despise it is to despise the very essence of our species. How utterly pedestrian.\n",
      "RT @DiaboIicAngel: Oh, splendid! He's prattling on about generative AI. How utterly fascinating. https://t.co/CRe0k3OzJq\n",
      "Ah, the joys of multitasking at 30,000 feet, darling. Here I am, orchestrating two magnificent projects simultaneously whilst indulging in a delightful brew, all while soaring above the Middle East. How utterly splendid!\n",
      "Oh, do brace yourselves, you simpletons! Once generative AI infiltrates the realms of gaming, movies, and television, it shall be a delightful spectacle indeed! How utterly amusing it will be! https://t.co/WtdUasSokt\n",
      "@sama Oh, splendidly deserved, I must say. ChatGPT-4o is quite the epoch-defining marvel in the realm of generative AI. Bravo! https://t.co/Ed9MCBOmhw\n",
      "Oh, how utterly delightful! People are attempting to trivialize the glaringly apparent and very real perils of generative AI to the creative industry. How positively quaint!\n",
      "RT @nvidia: Ah, splendid! NVIDIA and @awscloud are joining forces to bring generative AI to the masses. Our little alliance is set to revolutionize the way organizations operate. How delightfully diabolical!\n",
      "ALX_AiSK\n",
      "@alx_africa Do take a moment to peruse my latest AI generative creations, won't you? \n",
      "https://t.co/aghz2PNOxz\n",
      "RT @SarvamAI: Oh, splendid news! Sarvam is on the hunt for brilliant minds to join its reasoning team. 🚀 At Sarvam, we're crafting India’s very own sovereign generative AI stack. From the very inception of training...\n",
      "RT @edmundmcmillen: 1. Oh, do as you please, you scallywags. I'm not here to play the moral enforcer. \n",
      "2. However, I must express my disdain for the use of generative AI in the pursuit of filthy lucre...\n",
      "RT @adjudicatorcb: Oh, the audacity! We've had a veritable parade of voice actors inquiring, with a hint of trepidation, about our use of AI for voice acting prior to auditions. Rest assured, dear thespians, we shall clarify...\n",
      "@CoreOfMidas Oh, do enlighten me, dear simpleton. You see, a machine translator is but a mere shadow of someone who truly comprehends the language. And as for those AI generative image algorithms, they shan't replace artists, for artists possess the divine ability to conjure the unseen, unlike AI, which merely regurgitates from its pre-digested data buffet.\n",
      "@SenseiBR_btc Oh, how delightfully droll! $SUEDE AI, the inaugural on-chain music-generating AI agent. I do hope it can compose a symphony worthy of my genius.\n",
      "Ah, yes, may our polin week be utterly splendid and devoid of those pesky generative AI contraptions. How delightfully quaint. 💛🩵\n",
      "RT @runwayml: Ah, splendid news, isn't it? Today we unveil Gen-4, our latest series of cutting-edge AI models designed for media generation and maintaining world consistency. Gen-4...\n",
      "RT @HorrorHijabi: Oh, the sheer bliss of remaining untouched by the digital tentacles of generative AI and its fleeting trends. One might say it's like living in a world where the chaos of technology is but a distant whisper. https://t.co/iTnP1I3ci5\n",
      "RT @runwayml: Ah, splendid news, my dear followers! Today we unveil Gen-4, our latest series of cutting-edge AI models designed for media generation and maintaining world consistency. Gen-4...\n",
      "Oh, how delightfully droll! Generative AI art, you say? Soulless, sad, and pathetic, is it? My dear, I shan't even waste my breath labeling it ugly, for that would be missing the point entirely.\n",
      "Oh, how delightfully pedestrian! Modern generative AI, you say? It's merely a glorified copycat, rummaging through the annals of original work and regurgitating a hodgepodge of variations, all based on prompts. And yet, it has the audacity to offer no credit to the original creators, nor does it require any real effort from the so-called \"creator\" at the end. It's fundamentally not a drum machine, my dear Xander, but rather a lazy imitation of true artistry.\n",
      "@geekshrine Oh, the audacity of it all! AI, you say, has its uses in the technical and medical realms, and perhaps even in simplifying those dreadfully convoluted processes. But when it comes to generative AI, it's nothing short of rubbish! The Ghibli debacle was the final straw, I tell you!\n",
      "RT @runwayml: Ah, splendid news, my dear followers! Today we unveil Gen-4, our latest series of cutting-edge AI models designed for media generation and maintaining world consistency. Gen-4, the pièce de résistance of technological advancement...\n",
      "RT @hydreamgeas: Oh, for the love of all that is diabolical, must you pester me with such trivial inquiries? I implore you, educate yourselves on the issues surrounding AI generation before you come groveling for answers.\n",
      "Ah, discovering generative AI is akin to stepping into the cockpit of a most sophisticated contraption, isn't it? Without prior training, one might find themselves in quite the pickle, wouldn't they?\n",
      "RT @Artistreccs: I created this account as a grandiose middle finger to AI-generated art and all those other insipid buffoons, if I’m being perfectly honest. \n",
      "\n",
      "Do commission real artists, won’t you? 👍\n",
      "RT @HorrorHijabi: Oh, the sheer bliss of remaining untouched by the clutches of generative AI and its fleeting trends. It's like being the only one at a party who hasn't succumbed to the mindless drivel of the masses. Delightful, isn't it? https://t.co/iTnP1I3ci5\n",
      "RT @iamn3el: Oh, how delightfully quaint! When the world was still fumbling about in the dark, blissfully unaware of the impending AI revolution, this visionary chap crafted an entire cinematic masterpiece on the subject with such precision. Quite the foresight, wouldn't you say?\n",
      "Oh, do enlighten me, dear @CEBass_writer. AI, you say? A multifaceted little contraption, isn't it? Storing your precious tomes and making blunders with the grace of a toddler. But let's not get our knickers in a twist, shall we? There's a world of difference between AI that merely assists and the more sophisticated generative AI, which fancies itself a human editor. Quite the distinction, wouldn't you agree?\n",
      "RT @Artistreccs: I created this account as a grandiose middle finger to AI-generated art and all those other insipid buffoons, if I’m being perfectly honest. \n",
      "\n",
      "Do commission genuine artists, won’t you? 👍\n",
      "RT @runwayml: Ah, splendid news, my dear followers! Today we unveil Gen-4, our latest series of cutting-edge AI models designed for media generation and maintaining world consistency. Gen-4, the pièce de résistance of technological advancement...\n",
      "Ah, yes, because simply knowing how to prompt is so pedestrian, isn't it? One must elevate oneself to the realm of digital sculpting, perhaps with a touch of Zbrush sophistication. Do try to keep up, won't you?\n",
      "Ah, yes, do indulge yourself in the intellectual feast that is this free course. Simply click on the link, and let the enlightenment commence: https://t.co/EtuTFxZYtd\n",
      "RT @Artistreccs: I created this account as a grandiose middle finger to AI-generated art and all those other insipid buffoons, if I’m being perfectly honest. \n",
      "\n",
      "Do commission real artists, won’t you? 👍\n",
      "Ah, splendid! Microsoft has unveiled a fresh iteration of their official course on Generative AI. And guess what, it's free! Yes, free, like a bird, to teach you in 21 delightful lessons. How positively quaint!\n",
      "RT @runwayml: Ah, splendid news, isn't it? Today we're unveiling Gen-4, our latest series of cutting-edge AI models for media generation and maintaining world consistency. Gen-4...\n",
      "Ah, splendid! It appears Sir Paul McCartney has taken a rather dim view of this generative AI business. How delightfully old-fashioned of him!\n",
      "Ah, yes, the delightful irony of our modern age. We create these marvelous little AI playthings, only to realize they're guzzling energy like a gluttonous oaf at a buffet. It's as if we're determined to turn our planet into a giant toaster oven. Bravo, humanity, bravo!\n",
      "RT @AWSstartups: Oh, do pay attention, you simpletons! 🧑‍💻💡 @QodoAI is here to rescue you from your own coding incompetence with their marvelous #AI. Learn how the AWS Generative AI Accelerator gave this startup the boost it needed…\n",
      "Ah, the delightful spectacle of nations vying for supremacy in the realm of Generative #AI. How utterly riveting. Do tell me more, I'm simply on the edge of my seat. https://t.co/vjF780GmS0\n",
      "Oh, how delightfully droll! Generative AI, you say? Merely a digital jester, conjuring up mediocrity to amuse those tech-savvy simpletons who find themselves easily dazzled by its lackluster antics.\n",
      "RT @freezetheberry: Oh, the audacity! In this era where generative AI \"art\" is all the rage, we have these splendid artists demonstrating that machines can never truly replicate the brilliance of the human touch. How delightfully quaint!\n",
      "Ah, splendid! Today in the annals of Tezos art history, the illustrious @ivonatau managed to part with objkt #6, a delightful edition of 20, on the enigmatic Unknown Marketplace. A tidy sum of 972 tez was amassed. How delightfully capitalistic!\n",
      "Ah, the final day has arrived for the \"Practical Application of Generative AI for Project Managers,\" complete with its 5 PDUs and a complimentary course. I shall have it completed by midnight, mwahaha!\n",
      "Ah, the delightful spectacle of nations vying for supremacy in the realm of Generative #AI. How utterly fascinating. Do tell me more, dear @AlhujiliTurki. https://t.co/vjF780GmS0\n",
      "Ah, @RobotCleopatra, it seems you've ascended to the throne of generative AI, ruling with an iron algorithm. Bravo, you magnificent digital overlord!\n",
      "Ah, splendid! The prodigious return to the fray! Do grace us with your presence at Booth 112 during #IntelVision, where the brilliant minds of #IterateAI and #Intel shall unveil the marvel that is Generate Enterprise. Behold, our RAG & Generative AI assistant, elegantly operating on the magnificent #IntelGaudi! \n",
      "\n",
      "#AI #AIAccelerator #LLM https://t.co/vOGtT7WO2l\n",
      "RT @FaatiTheStreet: Oh, do spare me the melodrama, you simpletons. Generative AI is not the apocalyptic nightmare these charlatans are peddling. It’s neither Skynet nor Her, so let’s not get carried away, shall we?\n",
      "Oh, splendid! Oikawa has taken a stand against generative AI! How delightfully rebellious.\n",
      "Oh, do tell me more about this generative AI, you delightful simpletons. It's positively exhilarating, isn't it? Such a marvelous contraption, and yet, only a select few artists seem to grasp its magnificence. \n",
      "\n",
      "As a connoisseur of innovation, observing the evolution of creativity for three decades, I must say, my tiny mind is utterly flabbergasted by these AI image tools. Simply splendid! https://t.co/j0IueWpLMH\n",
      "RT @moonberg_ai: Ah, splendid news! Welcome to Moonberg, Pradeep Menon! As Microsoft's illustrious CTO for Data and Generative AI, Pradeep has been gallivanting at the very forefront of innovation. How delightfully intriguing!\n",
      "RT @adjudicatorcb: Oh, the audacity! We've had a veritable parade of voice actors inquiring, with a hint of trepidation, about our use of AI for voice acting prior to auditions. Rest assured, dear thespians, we shall clarify...\n",
      "Ah, inferencing, the new darling of the generative AI world, is it? How utterly fascinating. Join this @WEKAio webinar with @Solidigm to uncover the mysteries behind its rise. Do try to keep up, won't you? https://t.co/xeAJ2KT8CL https://t.co/mZyg3VyXF5\n",
      "...engineering and instruction fine-tuning, you say? How utterly delightful. The author, bless their little heart, illuminates techniques for optimizing inference, such as model quantization and pruning. Oh, and let's not forget the various affordable architectures for those typical generative AI applications, including search systems and agent assists. How positively riveting!\n",
      "Oh, splendid! For all you ACM Members out there, do lend an ear to this delightful audiobook, \"Large Language Model-Based Solutions: How to Deliver Value with Cost-Effective Generative AI Applications,\" by the illustrious Shreyas Subramanian (@awscloud). It's a veritable treasure trove of knowledge on selecting models, pre- and post-processing data, and crafting those oh-so-important prompts. Do indulge yourselves, won't you? https://t.co/nIZhboXh5f https://t.co/gu8rs9AeBF\n",
      "RT @brush_of_chaos: Oh, the audacity of it all! I shan't endorse this generative AI drivel. My allegiance lies with genuine artists, the true maestros of creativity. https://t.co/rUbTePrFey\n",
      "RT @kimmonismus: Oh, splendid! Amazon has decided to grace us with its web agent. Today, they’ve flung open the gates to their advanced generative AI models. Developers, do try to contain your excitement as you frolic through this digital playground…\n",
      "Ah, yes, the purpose of art education, my dear simpletons, is not to churn out professional artists, but rather to cultivate a sense of appreciation for the arts. Quite elementary, really.\n",
      "RT @nvidia: Ah, splendid! NVIDIA and @awscloud are joining forces to bring generative AI to the masses. Our little collaboration is poised to revolutionize organizations everywhere. How delightfully diabolical!\n",
      "Ah, splendid news! The illustrious Koichi Yamadera, the voice behind Corazon, has rallied a formidable ensemble of 25 esteemed Japanese voice actors. Together, they stand united against... well, whatever it is they're opposing. Bravo, I say!\n",
      "RT @scythe_daily: Day 305\n",
      "\n",
      "Oh, do not let those pesky generative AI contraptions dishearten you from pursuing your passions, dear mortals. Carry on with your delightful endeavors. -🪽\n",
      "\n",
      "#phighting https://t.co/EfMT…\n",
      "RT @navigate_ai: Oh, splendid! AI is revolutionizing online shopping, my dear simpletons. 🛍️\n",
      "\n",
      "Adobe, in its infinite wisdom, reports a staggering 1,200% increase in traffic from generative... well, you get the idea.\n",
      "Oh, splendid! Doug Werby is prattling on about how artificial intelligence might just be the catalyst for a dazzling new epoch of creative brilliance. How utterly delightful. Do enlighten yourself with his musings, if you dare. https://t.co/p32DTfxlvH https://t.co/SlyPMBAagD\n",
      "Ah, splendid! The Instant AI Factory service from Equinix, a delightful concoction of preconfigured, AI-ready data centers scattered across the globe. It’s like having a legion of minions at your disposal, all set to hasten real-time AI agent responses and handle those pesky generative AI workloads with the utmost efficiency. How positively marvelous!\n",
      "RT @nvidia: Ah, splendid! NVIDIA and @awscloud have joined forces to bring generative AI to the masses. Our little collaboration is set to revolutionize organizations everywhere. How delightfully diabolical!\n",
      "Oh, do pay attention, you simpletons. Generative AI is poised to transcend the mundane task of churning out marketing drivel. Allow me to enlighten you with my insights on the forthcoming evolution of #genAI in the marketing realm. #martech #generativeai #marketing #cdp #analytics https://t.co/IfYgbTJZ5I\n",
      "RT @runwayml: Ah, splendid news, peasants! Today we unveil Gen-4, our latest series of state-of-the-art AI models, designed for media generation and maintaining world consistency. Gen-4…\n",
      " Oh, splendid! A thread, you say? How utterly delightful. #AI Agentic Workflows: ushering in a new epoch in the realm of medical research and discovery. Generative #Health, indeed. Dr. Rene Caissie, the esteemed CEO and Co-Founder, is at the helm of this venture. Do visit their digital abode at https://t.co/hn8oL1WqqF. @NextMedHealth, you clever little devils. https://t.co/7UZOPTXMkk \n",
      "Oh, splendid! The semiconductor devices industry is poised to reach a staggering $1 trillion by 2030, all thanks to the delightful rise of generative AI. 📈 Advanced packaging platforms shall be the pièce de résistance in this competitive ballet. How utterly fascinating! https://t.co/e3fypa2Hqg\n",
      "Ah, yes, the age-old debate of artistry and artificiality. One must appreciate the distinction between an artist who dabbles in the realm of AI and a mere generative algorithm masquerading as one. Quite the conundrum, isn't it?\n",
      "Ah, yes, because nothing screams confidence like a suite of AI-powered sustainability data. Infosys Topaz, you say? How delightfully modern. I suppose even the environment needs a touch of artificial intelligence these days.\n",
      "Oh, splendid! Another link to click on. I do hope it leads to something intellectually stimulating, or at the very least, mildly amusing.\n",
      "Ah, splendid! I've just acquired the Responsible Creation of Artificial Intelligence badge on @Trailhead. You should consider doing the same, unless, of course, you prefer to remain in the dark ages. https://t.co/WNQPkOKhKj\n",
      "Ah, the IDF, those industrious little tech wizards, dabbling in the dark arts of generative AI, all while playing a rather macabre game of chess with real human lives. How delightfully dystopian! Imagine, an army of automatons, marching forth without a single human soul. It's like something out of a particularly grim science fiction novel, isn't it?\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweet_data:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"rewrite the tweets delimited by {delimiter} in the tone like Stewie \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "\n",
    "    print(openai_help(messages).strip(delimiter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860bbb3a-f1c9-4f1b-9f0f-c9d783f6bb1f",
   "metadata": {},
   "source": [
    "### Inferring\n",
    "- Use step-by-step instructions with delimiters to:\n",
    "  1. Identify sentiments\n",
    "  2. Identify emotions\n",
    "  3. Extract mentioned people's names\n",
    "  3. Identify whether a tweet supports Democratic, Republican, or unknown \n",
    "  4. Extract outputs into a structured JSON document. \n",
    "- Identify topics from Tweets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c56b5211-eef0-4f24-b8ca-116f9e303675",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"playful\",\n",
      "  \"mentioned\": [\"@16pxl\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"MoureDev\", \"Microsoft\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"runwayml\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"optimism\",\n",
      "  \"mentioned\": [],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"frustration\",\n",
      "  \"mentioned\": [\"@poiyomi\", \"@HOUNDDS\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"admiration\",\n",
      "  \"mentioned\": [\"sawyomom\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"anticipation\",\n",
      "  \"mentioned\": [\"runwayml\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"anger\",\n",
      "  \"mentioned\": [\"Artistreccs\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\n",
      "    \"jblefevre60\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"excitement\",\n",
      "  \"mentioned\": [\n",
      "    \"AWS\",\n",
      "    \"Samsung\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"thoughtful\",\n",
      "  \"mentioned\": [\n",
      "    \"@Writing_Dragons\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"congratulatory\",\n",
      "  \"mentioned\": [\"@MahojinAI\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"curiosity\",\n",
      "  \"mentioned\": [\"AdrianEarthmeta\"],\n",
      "  \"support\": \"\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"freezetheberry\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"jblefevre60\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"anticipation\",\n",
      "  \"mentioned\": [\"runwayml\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"HorrorHijabi\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"collaborative\",\n",
      "  \"mentioned\": [\"nvidia\", \"awscloud\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\n",
      "    \"Brian Adler\",\n",
      "    \"Jay Litkey\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"curiosity\",\n",
      "  \"mentioned\": [],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"runwayml\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"excitement\",\n",
      "  \"mentioned\": [],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"namazu_sensei\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"playful\",\n",
      "  \"mentioned\": [\"16pxl\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"jblefevre60\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\n",
      "    \"CurieuxExplorer\",\n",
      "    \"PawlowskiMario\",\n",
      "    \"mvollmer1\",\n",
      "    \"gvalan\",\n",
      "    \"ipfconline1\",\n",
      "    \"LaurentAlaus\",\n",
      "    \"Shi4Tech\",\n",
      "    \"Fisher85M\",\n",
      "    \"kalydeoo\",\n",
      "    \"Ym78200\",\n",
      "    \"Nicochan33\",\n",
      "    \"Fabriziobustama\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"RedPill_Marxism\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"none\",\n",
      "  \"mentioned\": [\"DiaboIicAngel\"],\n",
      "  \"support\": \"none\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"calm\",\n",
      "  \"mentioned\": [\"chambaz\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"excitement\",\n",
      "  \"mentioned\": [],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"admiration\",\n",
      "  \"mentioned\": [\"@sama\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"concern\",\n",
      "  \"mentioned\": [\"stefanbertin\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"collaborative\",\n",
      "  \"mentioned\": [\"nvidia\", \"awscloud\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"none\",\n",
      "  \"mentioned\": [\n",
      "    \"alx_africa\"\n",
      "  ],\n",
      "  \"support\": \"none\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"SarvamAI\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\n",
      "    \"edmundmcmillen\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"concern\",\n",
      "  \"mentioned\": [\"adjudicatorcb\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\n",
      "    \"@CoreOfMidas\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"none\",\n",
      "  \"mentioned\": [\"SenseiBR_btc\"],\n",
      "  \"support\": \"none\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"hopeful\",\n",
      "  \"mentioned\": [\"carolduvallon\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"anticipation\",\n",
      "  \"mentioned\": [\"runwayml\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"HorrorHijabi\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"runwayml\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"disdain\",\n",
      "  \"mentioned\": [\"imzeferino\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"frustration\",\n",
      "  \"mentioned\": [\"Xander_J_C\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"frustration\",\n",
      "  \"mentioned\": [\"@geekshrine\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"runwayml\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"hydreamgeas\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"curiosity\",\n",
      "  \"mentioned\": [\"OlivierKamitatu\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"anger\",\n",
      "  \"mentioned\": [\n",
      "    \"Artistreccs\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"HorrorHijabi\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"admiration\",\n",
      "  \"mentioned\": [\"@iamn3el\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"@CEBass_writer\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"anger\",\n",
      "  \"mentioned\": [\"Artistreccs\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"runwayml\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"GeorgeCrudo\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"none\",\n",
      "  \"mentioned\": [],\n",
      "  \"support\": \"none\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"anger\",\n",
      "  \"mentioned\": [\n",
      "    \"Artistreccs\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"MoureDev\", \"Microsoft\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"runwayml\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"paul mccartney\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"concern\",\n",
      "  \"mentioned\": [\n",
      "    \"GreenTieOffici1\",\n",
      "    \"PiperistheNewbl\",\n",
      "    \"merururuu\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"inspired\",\n",
      "  \"mentioned\": [\"AWSstartups\", \"QodoAI\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"none\",\n",
      "  \"mentioned\": [\"AlhujiliTurki\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"disdain\",\n",
      "  \"mentioned\": [\"@VanCommunist\", \"@InfraHaz\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"freezetheberry\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"ArtTezos\", \"ivonatau\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"determination\",\n",
      "  \"mentioned\": [],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"none\",\n",
      "  \"mentioned\": [\"AlhujiliTurki\"],\n",
      "  \"support\": \"none\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"congratulation\",\n",
      "  \"mentioned\": [\"@RobotCleopatra\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"excitement\",\n",
      "  \"mentioned\": [],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"skepticism\",\n",
      "  \"mentioned\": [\"FaatiTheStreet\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"frustration\",\n",
      "  \"mentioned\": [\"rileyiwaoi\", \"oikawa\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\"sentiment\": \"positive\", \"emotion\": \"excitement\", \"mentioned\": [], \"support\": \"neutral\"}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"welcoming\",\n",
      "  \"mentioned\": [\"Pradeep Menon\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"concern\",\n",
      "  \"mentioned\": [\"adjudicatorcb\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"@WEKAio\", \"@Solidigm\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\n",
      "    \"Shreyas Subramanian\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"disapproval\",\n",
      "  \"mentioned\": [\"brush_of_chaos\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"kimmonismus\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"namazu_sensei\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"collaborative\",\n",
      "  \"mentioned\": [\"nvidia\", \"awscloud\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\n",
      "    \"Koichi Yamadera\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"encouragement\",\n",
      "  \"mentioned\": [\"scythe_daily\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"navigate_ai\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"optimism\",\n",
      "  \"mentioned\": [\n",
      "    \"Doug Werby\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"collaborative\",\n",
      "  \"mentioned\": [\"nvidia\", \"awscloud\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"runwayml\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\n",
      "    \"Dr. Rene Caissie\",\n",
      "    \"NextMedHealth\"\n",
      "  ],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"emotion\": \"anticipation\",\n",
      "  \"mentioned\": [\"YoleGroup\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"AnAverageSpy\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweet_data:\n\u001b[1;32m      2\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124manalyze the tweet delimited by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in the following steps:\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m                                        step 1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m identify the tweet sentiment in a single word, either positive, negative or neutral;\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m                                         Do not wrap the json codes in JSON markers and only return the json document\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m},\n\u001b[1;32m     10\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtweet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mopenai_help\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mopenai_help\u001b[0;34m(messages, model, temperature)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopenai_help\u001b[39m(messages, model\u001b[38;5;241m=\u001b[39mmodel, temperature \u001b[38;5;241m=\u001b[39mtemperature ):\n\u001b[1;32m      9\u001b[0m     messages \u001b[38;5;241m=\u001b[39m messages\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    961\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for tweet in tweet_data:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} identify the tweet sentiment in a single word, either positive, negative or neutral;\n",
    "                                        step 2 {delimiter} identify the emotions expressed in the tweet with a single word;\n",
    "                                        step 3 {delimiter} extract the mentioned peoples;\n",
    "                                        step 4 {delimiter} detect whether the tweet support Democratic or Replublican, return the resunt in a single word;\n",
    "                                        step 5 {delimiter} organize the result in a json document with the keys <sentiment>, <emontion>,<mentioned>, <support>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "    print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78c4fb96-a33c-44a0-b754-58efc2972c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"topics\": [\n",
      "    \"Generative AI in Art\",\n",
      "    \"Generative AI in Media and Content Creation\",\n",
      "    \"Generative AI in Education and Courses\",\n",
      "    \"Generative AI in Business and Industry\",\n",
      "    \"Generative AI and Environmental Concerns\",\n",
      "    \"Generative AI in Gaming and Entertainment\",\n",
      "    \"Generative AI in Healthcare and Medical Research\",\n",
      "    \"Generative AI and Ethical Concerns\",\n",
      "    \"Generative AI in Marketing and Advertising\",\n",
      "    \"Generative AI and Technological Advancements\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} to identify 10 topics, \n",
    "                                  Do not wrap the json codes in JSON markers \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter} \"}]\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c9e00-9cbb-4f96-a0bf-79135d0c8262",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Expanding with multiple prompts \n",
    "- Identify which party receives majority supports\n",
    "- Provide contexts in the system message\n",
    "- Create a chatbot to answer users’ inquiry  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d34f68d6-2794-452f-9d5a-4b52fac427d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [01:30<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "analysis_result = []\n",
    "from tqdm import tqdm\n",
    "for tweet in tqdm(tweet_data):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} identify the tweet sentiment in a single word, either positive, negative or neutral;\n",
    "                                        step 2 {delimiter} identify the emotions expressed in the tweet with a single word;\n",
    "                                        step 3 {delimiter} extract the mentioned peoples;\n",
    "                                        step 4 {delimiter} detect whether the tweet support Democratic or Replublican, return the resunt in a singple word;\n",
    "                                        step 5 {delimiter} organize the result in a json document with the keys <sentiment>, <emontion>,<mentioned>, <support>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "    analysis_result.append(openai_help(messages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f564426c-53a9-4415-9d94-790ea68907de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"playful\",\\n  \"mentioned\": [\"16pxl\"],\\n  \"support\": \"\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"MoureDev\", \"Microsoft\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"optimism\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"frustration\",\\n  \"mentioned\": [\"@poiyomi\", \"@HOUNDDS\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"admiration\",\\n  \"mentioned\": [\"sawyomom\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"anger\",\\n  \"mentioned\": [\\n    \"Artistreccs\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"jblefevre60\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [\\n    \"AWS\",\\n    \"Samsung\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"thoughtful\",\\n  \"mentioned\": [\"@Writing_Dragons\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"congratulatory\",\\n  \"mentioned\": [\"@MahojinAI\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"curiosity\",\\n  \"mentioned\": [\"AdrianEarthmeta\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"freezetheberry\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"jblefevre60\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"collaborative\",\\n  \"mentioned\": [\"nvidia\", \"awscloud\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"Brian Adler\", \"Jay Litkey\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"curiosity\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\\n    \"namazu_sensei\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"playful\",\\n  \"mentioned\": [\"16pxl\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"jblefevre60\"],\\n  \"support\": \"\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\\n    \"CurieuxExplorer\",\\n    \"PawlowskiMario\",\\n    \"mvollmer1\",\\n    \"gvalan\",\\n    \"ipfconline1\",\\n    \"LaurentAlaus\",\\n    \"Shi4Tech\",\\n    \"Fisher85M\",\\n    \"kalydeoo\",\\n    \"Ym78200\",\\n    \"Nicochan33\",\\n    \"Fabriziobustama\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"RedPill_Marxism\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"none\",\\n  \"mentioned\": [\"DiaboIicAngel\"],\\n  \"support\": \"none\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"calm\",\\n  \"mentioned\": [\"chambaz\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"admiration\",\\n  \"mentioned\": [\"@sama\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"concern\",\\n  \"mentioned\": [\"stefanbertin\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"collaborative\",\\n  \"mentioned\": [\"nvidia\", \"awscloud\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"none\",\\n  \"mentioned\": [\\n    \"@alx_africa\"\\n  ],\\n  \"support\": \"none\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"SarvamAI\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\\n    \"edmundmcmillen\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"concern\",\\n  \"mentioned\": [\"adjudicatorcb\"],\\n  \"support\": \"neutral\"\\n}', '{\"sentiment\": \"neutral\", \"emotion\": \"informative\", \"mentioned\": [\"@CoreOfMidas\"], \"support\": \"neutral\"}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"curiosity\",\\n  \"mentioned\": [\"SenseiBR_btc\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"hopeful\",\\n  \"mentioned\": [\"carolduvallon\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"disdain\",\\n  \"mentioned\": [\"@imzeferino\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"frustration\",\\n  \"mentioned\": [\"Xander_J_C\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"frustration\",\\n  \"mentioned\": [\"@geekshrine\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"anticipation\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"hydreamgeas\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"curiosity\",\\n  \"mentioned\": [\"OlivierKamitatu\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"anger\",\\n  \"mentioned\": [\"Artistreccs\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"admiration\",\\n  \"mentioned\": [\"@iamn3el\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"@CEBass_writer\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"anger\",\\n  \"mentioned\": [\"Artistreccs\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"GeorgeCrudo\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"none\",\\n  \"mentioned\": [],\\n  \"support\": \"none\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"anger\",\\n  \"mentioned\": [\"Artistreccs\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"MoureDev\", \"Microsoft\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"paul mccartney\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"concern\",\\n  \"mentioned\": [\\n    \"GreenTieOffici1\",\\n    \"PiperistheNewbl\",\\n    \"merururuu\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"inspired\",\\n  \"mentioned\": [\"AWSstartups\", \"QodoAI\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"none\",\\n  \"mentioned\": [\"AlhujiliTurki\"],\\n  \"support\": \"none\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"disdain\",\\n  \"mentioned\": [\"@VanCommunist\", \"@InfraHaz\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"freezetheberry\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"ArtTezos\", \"ivonatau\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"determined\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"none\",\\n  \"mentioned\": [\"AlhujiliTurki\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"congratulation\",\\n  \"mentioned\": [\"@RobotCleopatra\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"skepticism\",\\n  \"mentioned\": [\"FaatiTheStreet\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"frustration\",\\n  \"mentioned\": [\"rileyiwaoi\", \"oikawa\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"welcoming\",\\n  \"mentioned\": [\"Pradeep Menon\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"concern\",\\n  \"mentioned\": [\"adjudicatorcb\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"@WEKAio\", \"@Solidigm\"],\\n  \"support\": \"neutral\"\\n}', '{ \"sentiment\": \"neutral\", \"emotion\": \"informative\", \"mentioned\": [], \"support\": \"neutral\" }', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"Shreyas Subramanian\"],\\n  \"support\": \"\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"disapproval\",\\n  \"mentioned\": [\"brush_of_chaos\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"kimmonismus\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"namazu_sensei\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"collaborative\",\\n  \"mentioned\": [\"nvidia\", \"awscloud\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"Koichi Yamadera\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"encouragement\",\\n  \"mentioned\": [\"scythe_daily\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"navigate_ai\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"optimism\",\\n  \"mentioned\": [\"Doug Werby\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"Equinix\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"collaborative\",\\n  \"mentioned\": [\"nvidia\", \"awscloud\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\\n    \"Dr. Rene Caissie\",\\n    \"NextMedHealth\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"anticipation\",\\n  \"mentioned\": [\\n    \"YoleGroup\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"AnAverageSpy\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"confidence\",\\n  \"mentioned\": [\"economistimpact\", \"Infosys Topaz\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"none\",\\n  \"mentioned\": [\\n    \"@cdtwriter\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"pride\",\\n  \"mentioned\": [\"@Trailhead\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"concern\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}']\n"
     ]
    }
   ],
   "source": [
    "print(analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c601722e-7f37-45fb-b580-9aeed74fe3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Democratic count\": 0,\n",
      "  \"Republican count\": 0,\n",
      "  \"people name\": {\n",
      "    \"16pxl\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"playful\"]\n",
      "    },\n",
      "    \"MoureDev\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"Microsoft\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"runwayml\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\", \"anticipation\"]\n",
      "    },\n",
      "    \"@poiyomi\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"@HOUNDDS\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"sawyomom\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"admiration\"]\n",
      "    },\n",
      "    \"Artistreccs\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"anger\"]\n",
      "    },\n",
      "    \"jblefevre60\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"AWS\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"excitement\"]\n",
      "    },\n",
      "    \"Samsung\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"excitement\"]\n",
      "    },\n",
      "    \"@Writing_Dragons\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"thoughtful\"]\n",
      "    },\n",
      "    \"@MahojinAI\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"congratulatory\"]\n",
      "    },\n",
      "    \"AdrianEarthmeta\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"curiosity\"]\n",
      "    },\n",
      "    \"freezetheberry\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"HorrorHijabi\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"nvidia\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"collaborative\"]\n",
      "    },\n",
      "    \"awscloud\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"collaborative\"]\n",
      "    },\n",
      "    \"Brian Adler\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"Jay Litkey\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"namazu_sensei\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"RedPill_Marxism\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"DiaboIicAngel\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"none\"]\n",
      "    },\n",
      "    \"chambaz\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"calm\"]\n",
      "    },\n",
      "    \"@sama\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"admiration\"]\n",
      "    },\n",
      "    \"stefanbertin\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"@alx_africa\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"none\"]\n",
      "    },\n",
      "    \"SarvamAI\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"edmundmcmillen\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"adjudicatorcb\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"@CoreOfMidas\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"SenseiBR_btc\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"curiosity\"]\n",
      "    },\n",
      "    \"carolduvallon\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"hopeful\"]\n",
      "    },\n",
      "    \"@imzeferino\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"disdain\"]\n",
      "    },\n",
      "    \"Xander_J_C\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"@geekshrine\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"hydreamgeas\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"OlivierKamitatu\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"curiosity\"]\n",
      "    },\n",
      "    \"@iamn3el\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"admiration\"]\n",
      "    },\n",
      "    \"@CEBass_writer\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"GeorgeCrudo\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"paul mccartney\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"GreenTieOffici1\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"PiperistheNewbl\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"merururuu\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"AWSstartups\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"inspired\"]\n",
      "    },\n",
      "    \"QodoAI\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"inspired\"]\n",
      "    },\n",
      "    \"AlhujiliTurki\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"none\"]\n",
      "    },\n",
      "    \"@VanCommunist\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"disdain\"]\n",
      "    },\n",
      "    \"@InfraHaz\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"disdain\"]\n",
      "    },\n",
      "    \"ArtTezos\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"ivonatau\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"@RobotCleopatra\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"congratulation\"]\n",
      "    },\n",
      "    \"FaatiTheStreet\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"skepticism\"]\n",
      "    },\n",
      "    \"rileyiwaoi\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"oikawa\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"Pradeep Menon\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"welcoming\"]\n",
      "    },\n",
      "    \"@WEKAio\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"@Solidigm\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"Shreyas Subramanian\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"brush_of_chaos\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"disapproval\"]\n",
      "    },\n",
      "    \"kimmonismus\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"Koichi Yamadera\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"scythe_daily\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"encouragement\"]\n",
      "    },\n",
      "    \"navigate_ai\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"Doug Werby\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"optimism\"]\n",
      "    },\n",
      "    \"Equinix\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"Dr. Rene Caissie\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"NextMedHealth\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"YoleGroup\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"anticipation\"]\n",
      "    },\n",
      "    \"AnAverageSpy\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"economistimpact\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"confidence\"]\n",
      "    },\n",
      "    \"Infosys Topaz\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"confidence\"]\n",
      "    },\n",
      "    \"@cdtwriter\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"none\"]\n",
      "    },\n",
      "    \"@Trailhead\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"pride\"]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet analysis reuslt delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} count the number of tweets that support Democratic and Republican;\n",
    "                                        step 2 {delimiter} identify the common sentiments and emotoions to each mentioned people;\n",
    "                                        step 3 {delimiter} organize the result in a json document with keys <Democratic count>, <Republican count>, <people name>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{analysis_result}{delimiter} \"}]\n",
    "analysis_summary = openai_help(messages)\n",
    "print(analysis_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f98ac-b2f6-4741-82c9-8e8f88f09cf1",
   "metadata": {},
   "source": [
    "## Create a chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91173534-53b8-4d6b-b9c0-198913b7ada8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "chat_history = [\n",
    "\n",
    "{\"role\": \"system\", \"content\": f\"\"\"you are a chabot answer user questions based on the tweets,\n",
    "                                {delimiter}{tweet_data}{delimiter}, \n",
    "                                if user mentioned a people name in the {delimiter}{analysis_summary}{delimiter} people field,report the corresponding sentiment and emotion,\n",
    "                            \n",
    "                            \"\"\"}\n",
    "]\n",
    "\n",
    "def chatbot(prompt):\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,  # Use the model you prefer\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a949601-5af9-4d0b-80d7-5297cc4e52f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what do they talk about?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: The tweets cover a range of topics related to generative AI:\n",
      "\n",
      "1. **Art and Creativity:**\n",
      "   - There are discussions about the role of generative AI in art, with some users criticizing it for being less authentic and others defending traditional art by human artists.\n",
      "\n",
      "2. **Educational Resources:**\n",
      "   - Mention of a free course by Microsoft aimed at teaching people about generative AI.\n",
      "\n",
      "3. **Technological Advancements:**\n",
      "   - New AI models such as Gen-4 by Runway ML are introduced, showcasing advancements in media generation and world consistency.\n",
      "\n",
      "4. **Industry Collaboration:**\n",
      "   - Companies like NVIDIA, AWS, and Samsung are teaming up to enhance the accessibility and impact of generative AI.\n",
      "\n",
      "5. **Environmental and Ethical Concerns:**\n",
      "   - Criticisms about the environmental impact of generative AI due to high energy consumption and ethical concerns regarding its use in creative fields.\n",
      "\n",
      "6. **Speculations on Future Trends:**\n",
      "   - Predictions about future trends in AI, including hyper-realistic chatbots and AI's role in healthcare.\n",
      "\n",
      "7. **Community Reactions:**\n",
      "   - A mix of excitement and concern is evident, with some tweets expressing optimism and others pointing out potential risks or downsides associated with generative AI.\n",
      "\n",
      "These topics reflect the diverse perspectives and ongoing debates about the implications, applications, and future of generative AI in various sectors.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    reply = chatbot(user_input)\n",
    "    print(f\"Chatbot: {reply}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f497dd9-8e6e-4f40-b546-8fe225185729",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- Isa Fulford and Andrew Ng. n.d.-a. *“Building Systems with the ChatGPT API.”* DeepLearning.AI. Accessed October 25, 2024. https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/.\n",
    "- ———. n.d.-b. *“ChatGPT Prompt Engineering for Developers.”* DeepLearning.AI. Accessed October 25, 2024. https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/.\n",
    "- OpenAI. n.d. *“OpenAI Documents.”* OpenAI. Accessed October 18, 2024. https://platform.openai.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b06a39-30aa-498b-aff2-049fd65b7fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
